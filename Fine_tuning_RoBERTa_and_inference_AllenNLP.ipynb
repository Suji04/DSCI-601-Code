{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Fine-tuning RoBERTa and inference AllenNLP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Gz0_YQUcHDD"
      },
      "source": [
        "# Installing necssary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVW6Lzj5QCZa"
      },
      "source": [
        "!pip install allennlp\n",
        "!pip install allennlp-models\n",
        "!pip install --upgrade google-cloud-storage"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHd3kdLjcP0u"
      },
      "source": [
        "# Fine-tuning RoBERTa on custom dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJR92RE3P9nq"
      },
      "source": [
        "!allennlp train snli_roberta.jsonnet -s /output_folder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvRaZJpRdXM4"
      },
      "source": [
        "# Loading fine-tuned model for predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNZZM3QCx111"
      },
      "source": [
        "from allennlp.predictors.predictor import Predictor\n",
        "predictor = Predictor.from_path(\"model.tar.gz\", \"textual_entailment\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9FQEu4leLh_"
      },
      "source": [
        "# Parallel inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Q-ItZpqYGva"
      },
      "source": [
        "def predict_multi(premise, hypothesis):\n",
        "    \n",
        "    try:\n",
        "        pred = predictor.predict(premise, hypothesis)\n",
        "        ans = pred['label']\n",
        "        print(ans)\n",
        "        \n",
        "    except:\n",
        "        ans = -1\n",
        "    return ans\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    data = pd.read_csv(str(channel) + \"-with-time.csv\") # CHANGE CSV FILENAME HERE\n",
        "\n",
        "    premise_list = data[\"sentence\"].values\n",
        "\n",
        "    # multiprocessing\n",
        "    st = time.time()\n",
        "    results = None\n",
        "    with multiprocessing.Pool(processes=3) as pool: # CHANGE NUMBER OF PROCESSES HERE\n",
        "        results = pool.map(partial(predict_multi, hypothesis=\"police protect us\"), premise_list) # CHANGE HYPOTHESIS HERE\n",
        "    data[\"police protect us\"] = results\n",
        "    pool.close()\n",
        "    data.to_csv(str(channel)+\"-with-time-results.csv\", index = False) # CHANGE OUTPUT FILENAME HERE\n",
        "    en = time.time()\n",
        "    print(\"time taken = \", en-st, \"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}